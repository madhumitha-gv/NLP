{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12467813,
          "sourceType": "datasetVersion",
          "datasetId": 7865598
        },
        {
          "sourceId": 12468324,
          "sourceType": "datasetVersion",
          "datasetId": 7865966
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhumitha-gv/NLP/blob/main/next_word_prediction_using_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T14:40:21.490306Z",
          "iopub.execute_input": "2025-07-14T14:40:21.491330Z",
          "iopub.status.idle": "2025-07-14T14:40:21.498917Z",
          "shell.execute_reply.started": "2025-07-14T14:40:21.491302Z",
          "shell.execute_reply": "2025-07-14T14:40:21.498247Z"
        },
        "id": "23MK9lzFrdwF"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zarZX2gAtpwC",
        "outputId": "6d03e339-45bb-4838-f576-574b8f3837aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import re"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:50:58.869598Z",
          "iopub.execute_input": "2025-07-14T15:50:58.870387Z",
          "iopub.status.idle": "2025-07-14T15:51:08.603164Z",
          "shell.execute_reply.started": "2025-07-14T15:50:58.870360Z",
          "shell.execute_reply": "2025-07-14T15:51:08.602557Z"
        },
        "id": "i8fwZSgLrdwG"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reading text file"
      ],
      "metadata": {
        "id": "0bhf3_MhrdwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/sherlock_output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:50:47.581847Z",
          "iopub.execute_input": "2025-07-14T15:50:47.582236Z",
          "iopub.status.idle": "2025-07-14T15:50:47.599692Z",
          "shell.execute_reply.started": "2025-07-14T15:50:47.582210Z",
          "shell.execute_reply": "2025-07-14T15:50:47.599128Z"
        },
        "id": "UxJ7IVVgrdwK"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# Load limited cleaned text to avoid RAM issues\n",
        "with open(\"sherlock_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# Basic cleanup\n",
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove punctuations\n",
        "text = re.sub(r'\\s+', ' ', text)  # normalize spaces"
      ],
      "metadata": {
        "id": "nlX9ef_lssfu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "5OXlmJ0erdwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer process\n",
        "tokenizer = Tokenizer()\n",
        "#fit\n",
        "tokenizer.fit_on_texts([text])\n",
        "#assign length of word index\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:51:14.167019Z",
          "iopub.execute_input": "2025-07-14T15:51:14.167629Z",
          "iopub.status.idle": "2025-07-14T15:51:14.707151Z",
          "shell.execute_reply.started": "2025-07-14T15:51:14.167605Z",
          "shell.execute_reply": "2025-07-14T15:51:14.706530Z"
        },
        "id": "HDeWIm4SrdwK"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "#chek the tokens\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:51:16.785669Z",
          "iopub.execute_input": "2025-07-14T15:51:16.786217Z",
          "iopub.status.idle": "2025-07-14T15:51:16.801905Z",
          "shell.execute_reply.started": "2025-07-14T15:51:16.786190Z",
          "shell.execute_reply": "2025-07-14T15:51:16.801121Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkdMbHybrdwK",
        "outputId": "64d5fb0c-9337-4dd7-ce10-0aefe9859ce9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'and': 3,\n",
              " 'to': 4,\n",
              " 'in': 5,\n",
              " 'a': 6,\n",
              " 'he': 7,\n",
              " 'that': 8,\n",
              " 'was': 9,\n",
              " 'it': 10,\n",
              " 'his': 11,\n",
              " 'is': 12,\n",
              " 'with': 13,\n",
              " 'as': 14,\n",
              " 'had': 15,\n",
              " 'i': 16,\n",
              " 'for': 17,\n",
              " 'at': 18,\n",
              " 'by': 19,\n",
              " 'on': 20,\n",
              " 'not': 21,\n",
              " 'be': 22,\n",
              " 'from': 23,\n",
              " 'but': 24,\n",
              " 'you': 25,\n",
              " 'or': 26,\n",
              " 'her': 27,\n",
              " 'him': 28,\n",
              " 'which': 29,\n",
              " 'were': 30,\n",
              " 'all': 31,\n",
              " 'this': 32,\n",
              " 'she': 33,\n",
              " 'they': 34,\n",
              " 'are': 35,\n",
              " 'have': 36,\n",
              " 'said': 37,\n",
              " 'an': 38,\n",
              " 'one': 39,\n",
              " 'who': 40,\n",
              " 'their': 41,\n",
              " 'so': 42,\n",
              " 'what': 43,\n",
              " 'when': 44,\n",
              " 'there': 45,\n",
              " 'am': 46,\n",
              " 'been': 47,\n",
              " 'may': 48,\n",
              " 'if': 49,\n",
              " 'no': 50,\n",
              " 'up': 51,\n",
              " 'my': 52,\n",
              " 'them': 53,\n",
              " 'into': 54,\n",
              " 'assetsdatacampcomproductionrepositoriesdatasetscabfafdfdsherlocktxt': 55,\n",
              " 'httpsassetsdatacampcomproductionrepositoriesdatasetscabfafdfdsherlocktxt': 56,\n",
              " 'its': 57,\n",
              " 'more': 58,\n",
              " 'out': 59,\n",
              " 'would': 60,\n",
              " 'me': 61,\n",
              " 'prince': 62,\n",
              " 'did': 63,\n",
              " 'only': 64,\n",
              " 'pierre': 65,\n",
              " 'we': 66,\n",
              " 'could': 67,\n",
              " 'now': 68,\n",
              " 'has': 69,\n",
              " 'will': 70,\n",
              " 'then': 71,\n",
              " 'some': 72,\n",
              " 'time': 73,\n",
              " 'man': 74,\n",
              " 'about': 75,\n",
              " 'after': 76,\n",
              " 'other': 77,\n",
              " 'do': 78,\n",
              " 'such': 79,\n",
              " 'before': 80,\n",
              " 'very': 81,\n",
              " 'how': 82,\n",
              " 'should': 83,\n",
              " 'your': 84,\n",
              " 'over': 85,\n",
              " 'than': 86,\n",
              " 'these': 87,\n",
              " 'new': 88,\n",
              " 'any': 89,\n",
              " 'those': 90,\n",
              " 'first': 91,\n",
              " 'himself': 92,\n",
              " 'well': 93,\n",
              " 'old': 94,\n",
              " 'face': 95,\n",
              " 'down': 96,\n",
              " 'upon': 97,\n",
              " 'men': 98,\n",
              " 'see': 99,\n",
              " 'natasha': 100,\n",
              " 'two': 101,\n",
              " 'our': 102,\n",
              " 'andrew': 103,\n",
              " 'french': 104,\n",
              " 'same': 105,\n",
              " 'know': 106,\n",
              " 'like': 107,\n",
              " 'without': 108,\n",
              " 'went': 109,\n",
              " 'made': 110,\n",
              " 'little': 111,\n",
              " 'came': 112,\n",
              " 'states': 113,\n",
              " 'where': 114,\n",
              " 'under': 115,\n",
              " 'must': 116,\n",
              " 'long': 117,\n",
              " 'eyes': 118,\n",
              " 'even': 119,\n",
              " 'come': 120,\n",
              " 'princess': 121,\n",
              " 'being': 122,\n",
              " 'room': 123,\n",
              " 'still': 124,\n",
              " 'go': 125,\n",
              " 'most': 126,\n",
              " 'thought': 127,\n",
              " 'can': 128,\n",
              " 'way': 129,\n",
              " 'again': 130,\n",
              " 'people': 131,\n",
              " 'war': 132,\n",
              " 'life': 133,\n",
              " 'away': 134,\n",
              " 'left': 135,\n",
              " 'hand': 136,\n",
              " 'another': 137,\n",
              " 'through': 138,\n",
              " 'began': 139,\n",
              " 'general': 140,\n",
              " 'great': 141,\n",
              " 'own': 142,\n",
              " 'asked': 143,\n",
              " 'also': 144,\n",
              " 'just': 145,\n",
              " 'day': 146,\n",
              " 'looked': 147,\n",
              " 'say': 148,\n",
              " 'while': 149,\n",
              " 'whole': 150,\n",
              " 'army': 151,\n",
              " 'american': 152,\n",
              " 'back': 153,\n",
              " 'shall': 154,\n",
              " 'head': 155,\n",
              " 'rostov': 156,\n",
              " 'moscow': 157,\n",
              " 'right': 158,\n",
              " 'part': 159,\n",
              " 'felt': 160,\n",
              " 'seemed': 161,\n",
              " 'us': 162,\n",
              " 'something': 163,\n",
              " 'yes': 164,\n",
              " 'count': 165,\n",
              " 'much': 166,\n",
              " 'place': 167,\n",
              " 'why': 168,\n",
              " 'having': 169,\n",
              " 'against': 170,\n",
              " 'here': 171,\n",
              " 'state': 172,\n",
              " 'between': 173,\n",
              " 'mary': 174,\n",
              " 'every': 175,\n",
              " 'house': 176,\n",
              " 'government': 177,\n",
              " 'heard': 178,\n",
              " 'nothing': 179,\n",
              " 'though': 180,\n",
              " 'off': 181,\n",
              " 'nicholas': 182,\n",
              " 'because': 183,\n",
              " 'young': 184,\n",
              " 'take': 185,\n",
              " 'always': 186,\n",
              " 'many': 187,\n",
              " 'saw': 188,\n",
              " 'good': 189,\n",
              " 'disease': 190,\n",
              " 'bone': 191,\n",
              " 'never': 192,\n",
              " 'years': 193,\n",
              " 'dont': 194,\n",
              " 'took': 195,\n",
              " 'look': 196,\n",
              " 'once': 197,\n",
              " 'last': 198,\n",
              " 'united': 199,\n",
              " 'think': 200,\n",
              " 'found': 201,\n",
              " 'skin': 202,\n",
              " 'round': 203,\n",
              " 'too': 204,\n",
              " 'met': 205,\n",
              " 'power': 206,\n",
              " 'might': 207,\n",
              " 'emperor': 208,\n",
              " 'three': 209,\n",
              " 'tissue': 210,\n",
              " 'small': 211,\n",
              " 'give': 212,\n",
              " 'both': 213,\n",
              " 'usually': 214,\n",
              " 'make': 215,\n",
              " 'side': 216,\n",
              " 'quite': 217,\n",
              " 'napoleon': 218,\n",
              " 'form': 219,\n",
              " 'during': 220,\n",
              " 'turned': 221,\n",
              " 'suddenly': 222,\n",
              " 'countess': 223,\n",
              " 'knew': 224,\n",
              " 'tell': 225,\n",
              " 'door': 226,\n",
              " 'told': 227,\n",
              " 'already': 228,\n",
              " 'whom': 229,\n",
              " 'large': 230,\n",
              " 'yet': 231,\n",
              " 'let': 232,\n",
              " 'love': 233,\n",
              " 'days': 234,\n",
              " 'moment': 235,\n",
              " 'get': 236,\n",
              " 'holmes': 237,\n",
              " 'chapter': 238,\n",
              " 'voice': 239,\n",
              " 'end': 240,\n",
              " 'russian': 241,\n",
              " 'few': 242,\n",
              " 'words': 243,\n",
              " 'blood': 244,\n",
              " 'hands': 245,\n",
              " 'looking': 246,\n",
              " 'cases': 247,\n",
              " 'kutuzov': 248,\n",
              " 'dear': 249,\n",
              " 'seen': 250,\n",
              " 'among': 251,\n",
              " 'often': 252,\n",
              " 'everything': 253,\n",
              " 'gave': 254,\n",
              " 'congress': 255,\n",
              " 'taken': 256,\n",
              " 'put': 257,\n",
              " 'battle': 258,\n",
              " 'officer': 259,\n",
              " 'position': 260,\n",
              " 'however': 261,\n",
              " 'history': 262,\n",
              " 'done': 263,\n",
              " 'case': 264,\n",
              " 'smile': 265,\n",
              " 'soon': 266,\n",
              " 'soldiers': 267,\n",
              " 'sometimes': 268,\n",
              " 'father': 269,\n",
              " 'called': 270,\n",
              " 'others': 271,\n",
              " 'each': 272,\n",
              " 'sonya': 273,\n",
              " 'country': 274,\n",
              " 'free': 275,\n",
              " 'become': 276,\n",
              " 'understand': 277,\n",
              " 'oh': 278,\n",
              " 'brought': 279,\n",
              " 'order': 280,\n",
              " 'sat': 281,\n",
              " 'behind': 282,\n",
              " 'along': 283,\n",
              " 'far': 284,\n",
              " 'course': 285,\n",
              " 'result': 286,\n",
              " 'stood': 287,\n",
              " 'especially': 288,\n",
              " 'anything': 289,\n",
              " 'known': 290,\n",
              " 'work': 291,\n",
              " 'evidently': 292,\n",
              " 'several': 293,\n",
              " 'cause': 294,\n",
              " 'going': 295,\n",
              " 'law': 296,\n",
              " 'passed': 297,\n",
              " 'less': 298,\n",
              " 'given': 299,\n",
              " 'denisov': 300,\n",
              " 'treatment': 301,\n",
              " 'certain': 302,\n",
              " 'matter': 303,\n",
              " 'mr': 304,\n",
              " 'feeling': 305,\n",
              " 'patient': 306,\n",
              " 'front': 307,\n",
              " 'does': 308,\n",
              " 'infection': 309,\n",
              " 'women': 310,\n",
              " 'whether': 311,\n",
              " 'action': 312,\n",
              " 'movement': 313,\n",
              " 'world': 314,\n",
              " 'herself': 315,\n",
              " 'question': 316,\n",
              " 'mind': 317,\n",
              " 'condition': 318,\n",
              " 'night': 319,\n",
              " 'possible': 320,\n",
              " 'officers': 321,\n",
              " 'white': 322,\n",
              " 'joint': 323,\n",
              " 'alone': 324,\n",
              " 'toward': 325,\n",
              " 'later': 326,\n",
              " 'president': 327,\n",
              " 'followed': 328,\n",
              " 'body': 329,\n",
              " 'necessary': 330,\n",
              " 'present': 331,\n",
              " 'morning': 332,\n",
              " 'until': 333,\n",
              " 'chief': 334,\n",
              " 'almost': 335,\n",
              " 'want': 336,\n",
              " 'things': 337,\n",
              " 'fig': 338,\n",
              " 'money': 339,\n",
              " 'expression': 340,\n",
              " 'ran': 341,\n",
              " 'replied': 342,\n",
              " 'sent': 343,\n",
              " 'troops': 344,\n",
              " 'set': 345,\n",
              " 'death': 346,\n",
              " 'became': 347,\n",
              " 'act': 348,\n",
              " 'labor': 349,\n",
              " 'use': 350,\n",
              " 'business': 351,\n",
              " 'within': 352,\n",
              " 'pp': 353,\n",
              " 'wife': 354,\n",
              " 'god': 355,\n",
              " 'south': 356,\n",
              " 'horse': 357,\n",
              " 'taking': 358,\n",
              " 'themselves': 359,\n",
              " 'leave': 360,\n",
              " 'above': 361,\n",
              " 'thing': 362,\n",
              " 'word': 363,\n",
              " 'number': 364,\n",
              " 'added': 365,\n",
              " 'pain': 366,\n",
              " 'son': 367,\n",
              " 'wound': 368,\n",
              " 'anna': 369,\n",
              " 'find': 370,\n",
              " 'open': 371,\n",
              " 'england': 372,\n",
              " 'either': 373,\n",
              " 'lay': 374,\n",
              " 'parts': 375,\n",
              " 'home': 376,\n",
              " 'near': 377,\n",
              " 'fact': 378,\n",
              " 'boris': 379,\n",
              " 'continued': 380,\n",
              " 'commander': 381,\n",
              " 'letter': 382,\n",
              " 'held': 383,\n",
              " 'party': 384,\n",
              " 'project': 385,\n",
              " 'common': 386,\n",
              " 'constitution': 387,\n",
              " 'talk': 388,\n",
              " 'national': 389,\n",
              " 'illustration': 390,\n",
              " 'dolokhov': 391,\n",
              " 'table': 392,\n",
              " 'cried': 393,\n",
              " 'tissues': 394,\n",
              " 'ill': 395,\n",
              " 'public': 396,\n",
              " 'woman': 397,\n",
              " 'got': 398,\n",
              " 'example': 399,\n",
              " 'carried': 400,\n",
              " 'thats': 401,\n",
              " 'america': 402,\n",
              " 'important': 403,\n",
              " 'horses': 404,\n",
              " 'received': 405,\n",
              " 'nor': 406,\n",
              " 'cannot': 407,\n",
              " 'entered': 408,\n",
              " 'west': 409,\n",
              " 'used': 410,\n",
              " 'surface': 411,\n",
              " 'second': 412,\n",
              " 'next': 413,\n",
              " 'different': 414,\n",
              " 'land': 415,\n",
              " 'around': 416,\n",
              " 'really': 417,\n",
              " 'saying': 418,\n",
              " 'early': 419,\n",
              " 'nerve': 420,\n",
              " 'fire': 421,\n",
              " 'year': 422,\n",
              " 'glands': 423,\n",
              " 'high': 424,\n",
              " 'itself': 425,\n",
              " 'better': 426,\n",
              " 'british': 427,\n",
              " 'light': 428,\n",
              " 'since': 429,\n",
              " 'evening': 430,\n",
              " 'union': 431,\n",
              " 'political': 432,\n",
              " 'name': 433,\n",
              " 'best': 434,\n",
              " 'together': 435,\n",
              " 'full': 436,\n",
              " 'half': 437,\n",
              " 'road': 438,\n",
              " 'thousand': 439,\n",
              " 'ever': 440,\n",
              " 'speak': 441,\n",
              " 'shouted': 442,\n",
              " 'mother': 443,\n",
              " 'cold': 444,\n",
              " 'arm': 445,\n",
              " 'bones': 446,\n",
              " 'sitting': 447,\n",
              " 'forms': 448,\n",
              " 'means': 449,\n",
              " 'arms': 450,\n",
              " 'ask': 451,\n",
              " 'kept': 452,\n",
              " 'friend': 453,\n",
              " 'due': 454,\n",
              " 'impossible': 455,\n",
              " 'petya': 456,\n",
              " 'line': 457,\n",
              " 'four': 458,\n",
              " 'becomes': 459,\n",
              " 'moved': 460,\n",
              " 'petersburg': 461,\n",
              " 'vessels': 462,\n",
              " 'rise': 463,\n",
              " 'rose': 464,\n",
              " 'wish': 465,\n",
              " 'heart': 466,\n",
              " 'gone': 467,\n",
              " 'conditions': 468,\n",
              " 'force': 469,\n",
              " 'tuberculous': 470,\n",
              " 'five': 471,\n",
              " 'times': 472,\n",
              " 'clear': 473,\n",
              " 'short': 474,\n",
              " 'longer': 475,\n",
              " 'remained': 476,\n",
              " 'laws': 477,\n",
              " 'results': 478,\n",
              " 'help': 479,\n",
              " 'hundred': 480,\n",
              " 'system': 481,\n",
              " 'fellow': 482,\n",
              " 'enemy': 483,\n",
              " 'third': 484,\n",
              " 'formed': 485,\n",
              " 'military': 486,\n",
              " 'drawing': 487,\n",
              " 'forward': 488,\n",
              " 'ready': 489,\n",
              " 'answered': 490,\n",
              " 'myself': 491,\n",
              " 'everyone': 492,\n",
              " 'rode': 493,\n",
              " 'beyond': 494,\n",
              " 'tried': 495,\n",
              " 'crowd': 496,\n",
              " 'regiment': 497,\n",
              " 'lost': 498,\n",
              " 'wounded': 499,\n",
              " 'hair': 500,\n",
              " 'understood': 501,\n",
              " 'orders': 502,\n",
              " 'growth': 503,\n",
              " 'across': 504,\n",
              " 'strange': 505,\n",
              " 'peace': 506,\n",
              " 'news': 507,\n",
              " 'reached': 508,\n",
              " 'north': 509,\n",
              " 'rather': 510,\n",
              " 'sound': 511,\n",
              " 'beside': 512,\n",
              " 'happy': 513,\n",
              " 'pressure': 514,\n",
              " 'frequently': 515,\n",
              " 'ah': 516,\n",
              " 'opinion': 517,\n",
              " 'spoke': 518,\n",
              " 'process': 519,\n",
              " 'opened': 520,\n",
              " 'interest': 521,\n",
              " 'presence': 522,\n",
              " 'service': 523,\n",
              " 'tumour': 524,\n",
              " 'rostovs': 525,\n",
              " 'past': 526,\n",
              " 'close': 527,\n",
              " 'ten': 528,\n",
              " 'limb': 529,\n",
              " 'formation': 530,\n",
              " 'read': 531,\n",
              " 'coming': 532,\n",
              " 'till': 533,\n",
              " 'vasili': 534,\n",
              " 'show': 535,\n",
              " 'point': 536,\n",
              " 'red': 537,\n",
              " 'king': 538,\n",
              " 'anyone': 539,\n",
              " 'children': 540,\n",
              " 'cant': 541,\n",
              " 'wanted': 542,\n",
              " 'trade': 543,\n",
              " 'field': 544,\n",
              " 'stopped': 545,\n",
              " 'thus': 546,\n",
              " 'raised': 547,\n",
              " 'wished': 548,\n",
              " 'repeated': 549,\n",
              " 'affairs': 550,\n",
              " 'turning': 551,\n",
              " 'anatole': 552,\n",
              " 'following': 553,\n",
              " 'black': 554,\n",
              " 'standing': 555,\n",
              " 'happened': 556,\n",
              " 'english': 557,\n",
              " 'true': 558,\n",
              " 'making': 559,\n",
              " 'rest': 560,\n",
              " 'applied': 561,\n",
              " 'perhaps': 562,\n",
              " 'talking': 563,\n",
              " 'answer': 564,\n",
              " 'operation': 565,\n",
              " 'seeing': 566,\n",
              " 'affected': 567,\n",
              " 'family': 568,\n",
              " 'muscles': 569,\n",
              " 'soldier': 570,\n",
              " 'period': 571,\n",
              " 'air': 572,\n",
              " 'occur': 573,\n",
              " 'colonies': 574,\n",
              " 'kind': 575,\n",
              " 'call': 576,\n",
              " 'able': 577,\n",
              " 'bed': 578,\n",
              " 'rapidly': 579,\n",
              " 'led': 580,\n",
              " 'associated': 581,\n",
              " 'deep': 582,\n",
              " 'appeared': 583,\n",
              " 'events': 584,\n",
              " 'southern': 585,\n",
              " 'returned': 586,\n",
              " 'neck': 587,\n",
              " 'york': 588,\n",
              " 'lower': 589,\n",
              " 'terrible': 590,\n",
              " 'cut': 591,\n",
              " 'aneurysm': 592,\n",
              " 'least': 593,\n",
              " 'spread': 594,\n",
              " 'else': 595,\n",
              " 'reason': 596,\n",
              " 'noticed': 597,\n",
              " 'lymph': 598,\n",
              " 'attention': 599,\n",
              " 'german': 600,\n",
              " 'local': 601,\n",
              " 'ff': 602,\n",
              " 'merely': 603,\n",
              " 'wall': 604,\n",
              " 'return': 605,\n",
              " 'silent': 606,\n",
              " 'steps': 607,\n",
              " 'effect': 608,\n",
              " 'laid': 609,\n",
              " 'giving': 610,\n",
              " 'company': 611,\n",
              " 'whose': 612,\n",
              " 'campaign': 613,\n",
              " 'foot': 614,\n",
              " 'revolution': 615,\n",
              " 'federal': 616,\n",
              " 'abscess': 617,\n",
              " 'window': 618,\n",
              " 'turn': 619,\n",
              " 'hear': 620,\n",
              " 'believe': 621,\n",
              " 'therefore': 622,\n",
              " 'person': 623,\n",
              " 'strength': 624,\n",
              " 'soft': 625,\n",
              " 'slavery': 626,\n",
              " 'placed': 627,\n",
              " 'subject': 628,\n",
              " 'quickly': 629,\n",
              " 'speaking': 630,\n",
              " 'russia': 631,\n",
              " 'immediately': 632,\n",
              " 'friends': 633,\n",
              " 'size': 634,\n",
              " 'questions': 635,\n",
              " 'trying': 636,\n",
              " 'colonial': 637,\n",
              " 'street': 638,\n",
              " 'city': 639,\n",
              " 'honor': 640,\n",
              " 'feet': 641,\n",
              " 'usual': 642,\n",
              " 'removed': 643,\n",
              " 'account': 644,\n",
              " 'former': 645,\n",
              " 'dinner': 646,\n",
              " 'fell': 647,\n",
              " 'conversation': 648,\n",
              " 'sir': 649,\n",
              " 'civil': 650,\n",
              " 'view': 651,\n",
              " 'nearly': 652,\n",
              " 'middle': 653,\n",
              " 'foreign': 654,\n",
              " 'tumours': 655,\n",
              " 'glanced': 656,\n",
              " 'forces': 657,\n",
              " 'enough': 658,\n",
              " 'doing': 659,\n",
              " 'wounds': 660,\n",
              " 'hardly': 661,\n",
              " 'hours': 662,\n",
              " 'fine': 663,\n",
              " 'sides': 664,\n",
              " 'severe': 665,\n",
              " 'republican': 666,\n",
              " 'tears': 667,\n",
              " 'character': 668,\n",
              " 'measures': 669,\n",
              " 'considerable': 670,\n",
              " 'particularly': 671,\n",
              " 'seat': 672,\n",
              " 'hard': 673,\n",
              " 'meet': 674,\n",
              " 'afraid': 675,\n",
              " 'town': 676,\n",
              " 'water': 677,\n",
              " 'remarked': 678,\n",
              " 'single': 679,\n",
              " 'wont': 680,\n",
              " 'freedom': 681,\n",
              " 'please': 682,\n",
              " 'paper': 683,\n",
              " 'closed': 684,\n",
              " 'neither': 685,\n",
              " 'symptoms': 686,\n",
              " 'pierres': 687,\n",
              " 'strong': 688,\n",
              " 'waiting': 689,\n",
              " 'de': 690,\n",
              " 'grew': 691,\n",
              " 'tone': 692,\n",
              " 'spirit': 693,\n",
              " 'bring': 694,\n",
              " 'husband': 695,\n",
              " 'human': 696,\n",
              " 'reply': 697,\n",
              " 'changes': 698,\n",
              " 'swelling': 699,\n",
              " 'rights': 700,\n",
              " 'nature': 701,\n",
              " 'ground': 702,\n",
              " 'fear': 703,\n",
              " 'thin': 704,\n",
              " 'according': 705,\n",
              " 'late': 706,\n",
              " 'soul': 707,\n",
              " 'france': 708,\n",
              " 'considered': 709,\n",
              " 'artery': 710,\n",
              " 'society': 711,\n",
              " 'yourself': 712,\n",
              " 'court': 713,\n",
              " 'doctor': 714,\n",
              " 'child': 715,\n",
              " 'except': 716,\n",
              " 'smiling': 717,\n",
              " 'area': 718,\n",
              " 'feel': 719,\n",
              " 'gangrene': 720,\n",
              " 'cancer': 721,\n",
              " 'need': 722,\n",
              " 'girl': 723,\n",
              " 'coat': 724,\n",
              " 'acute': 725,\n",
              " 'mouth': 726,\n",
              " 'faces': 727,\n",
              " 'village': 728,\n",
              " 'smiled': 729,\n",
              " 'joints': 730,\n",
              " 'bolkonski': 731,\n",
              " 'plan': 732,\n",
              " 'contrary': 733,\n",
              " 'remember': 734,\n",
              " 'adjutant': 735,\n",
              " 'boy': 736,\n",
              " 'listened': 737,\n",
              " 'fresh': 738,\n",
              " 'dead': 739,\n",
              " 'special': 740,\n",
              " 'bridge': 741,\n",
              " 'members': 742,\n",
              " 'finally': 743,\n",
              " 'dark': 744,\n",
              " 'lady': 745,\n",
              " 'lesions': 746,\n",
              " 'clinical': 747,\n",
              " 'six': 748,\n",
              " 'although': 749,\n",
              " 'pass': 750,\n",
              " 'bad': 751,\n",
              " 'employed': 752,\n",
              " 'drew': 753,\n",
              " 'washington': 754,\n",
              " 'syphilis': 755,\n",
              " 'doubt': 756,\n",
              " 'takes': 757,\n",
              " 'pale': 758,\n",
              " 'attack': 759,\n",
              " 'covered': 760,\n",
              " 'command': 761,\n",
              " 'nation': 762,\n",
              " 'various': 763,\n",
              " 'occurs': 764,\n",
              " 'change': 765,\n",
              " 'glad': 766,\n",
              " 'features': 767,\n",
              " 'appear': 768,\n",
              " 'growing': 769,\n",
              " 'membrane': 770,\n",
              " 'wrote': 771,\n",
              " 'hope': 772,\n",
              " 'showed': 773,\n",
              " 'described': 774,\n",
              " 'primary': 775,\n",
              " 'ulcer': 776,\n",
              " 'europe': 777,\n",
              " 'difficult': 778,\n",
              " 'voices': 779,\n",
              " 'decided': 780,\n",
              " 'powers': 781,\n",
              " 'fixed': 782,\n",
              " 'someone': 783,\n",
              " 'daughter': 784,\n",
              " 'st': 785,\n",
              " 'minutes': 786,\n",
              " 'john': 787,\n",
              " 'says': 788,\n",
              " 'unable': 789,\n",
              " 'independence': 790,\n",
              " 'liable': 791,\n",
              " 'russians': 792,\n",
              " 'pus': 793,\n",
              " 'secondary': 794,\n",
              " 'opening': 795,\n",
              " 'run': 796,\n",
              " 'direction': 797,\n",
              " 'lips': 798,\n",
              " 'brother': 799,\n",
              " 'relations': 800,\n",
              " 'convention': 801,\n",
              " 'ordered': 802,\n",
              " 'frightened': 803,\n",
              " 'natural': 804,\n",
              " 'killed': 805,\n",
              " 'virginia': 806,\n",
              " 'republicans': 807,\n",
              " 'suppuration': 808,\n",
              " 'complete': 809,\n",
              " 'hour': 810,\n",
              " 'cry': 811,\n",
              " 'fingers': 812,\n",
              " 'holding': 813,\n",
              " 'greater': 814,\n",
              " 'beginning': 815,\n",
              " 'causes': 816,\n",
              " 'moving': 817,\n",
              " 'muscle': 818,\n",
              " 'capital': 819,\n",
              " 'probably': 820,\n",
              " 'terms': 821,\n",
              " 'staff': 822,\n",
              " 'study': 823,\n",
              " 'serious': 824,\n",
              " 'remain': 825,\n",
              " 'carriage': 826,\n",
              " 'nerves': 827,\n",
              " 'keep': 828,\n",
              " 'loss': 829,\n",
              " 'firm': 830,\n",
              " 'leg': 831,\n",
              " 'happiness': 832,\n",
              " 'struck': 833,\n",
              " 'smoke': 834,\n",
              " 'method': 835,\n",
              " 'mademoiselle': 836,\n",
              " 'relation': 837,\n",
              " 'running': 838,\n",
              " 'ones': 839,\n",
              " 'idea': 840,\n",
              " 'declared': 841,\n",
              " 'haemorrhage': 842,\n",
              " 'heavy': 843,\n",
              " 'influence': 844,\n",
              " 'group': 845,\n",
              " 'increased': 846,\n",
              " 'further': 847,\n",
              " 'direct': 848,\n",
              " 'consists': 849,\n",
              " 'helene': 850,\n",
              " 'prepared': 851,\n",
              " 'indeed': 852,\n",
              " 'step': 853,\n",
              " 'drawn': 854,\n",
              " 'colonel': 855,\n",
              " 'lead': 856,\n",
              " 'pleasure': 857,\n",
              " 'silence': 858,\n",
              " 'vessel': 859,\n",
              " 'emperors': 860,\n",
              " 'march': 861,\n",
              " 'manner': 862,\n",
              " 'matters': 863,\n",
              " 'instead': 864,\n",
              " 'marked': 865,\n",
              " 'o': 866,\n",
              " 'changed': 867,\n",
              " 'simple': 868,\n",
              " 'dress': 869,\n",
              " 'appearance': 870,\n",
              " 'passing': 871,\n",
              " 'seems': 872,\n",
              " 'knee': 873,\n",
              " 'prevent': 874,\n",
              " 'duty': 875,\n",
              " 'leaders': 876,\n",
              " 'syphilitic': 877,\n",
              " 'bagration': 878,\n",
              " 'alpatych': 879,\n",
              " 'slowly': 880,\n",
              " 'living': 881,\n",
              " 'thinking': 882,\n",
              " 'lines': 883,\n",
              " 'popular': 884,\n",
              " 'property': 885,\n",
              " 'chiefly': 886,\n",
              " 'attended': 887,\n",
              " 'expressed': 888,\n",
              " 'produced': 889,\n",
              " 'age': 890,\n",
              " 'leaving': 891,\n",
              " 'f': 892,\n",
              " 'story': 893,\n",
              " 'observed': 894,\n",
              " 'besides': 895,\n",
              " 'months': 896,\n",
              " 'east': 897,\n",
              " 'term': 898,\n",
              " 'alexander': 899,\n",
              " 'twenty': 900,\n",
              " 'effort': 901,\n",
              " 'clearly': 902,\n",
              " 'angry': 903,\n",
              " 'injury': 904,\n",
              " 'industry': 905,\n",
              " 'generals': 906,\n",
              " 'series': 907,\n",
              " 'activity': 908,\n",
              " 'corner': 909,\n",
              " 'chair': 910,\n",
              " 'loved': 911,\n",
              " 'lord': 912,\n",
              " 'veins': 913,\n",
              " 'dry': 914,\n",
              " 'victory': 915,\n",
              " 'historians': 916,\n",
              " 'peasants': 917,\n",
              " 'upper': 918,\n",
              " 'similar': 919,\n",
              " 'low': 920,\n",
              " 'mans': 921,\n",
              " 'tendon': 922,\n",
              " 'wait': 923,\n",
              " 'live': 924,\n",
              " 'george': 925,\n",
              " 'gutenbergtm': 926,\n",
              " 'diseases': 927,\n",
              " 'shoulders': 928,\n",
              " 'pay': 929,\n",
              " 'poor': 930,\n",
              " 'future': 931,\n",
              " 'sight': 932,\n",
              " 'cells': 933,\n",
              " 'straight': 934,\n",
              " 'fall': 935,\n",
              " 'fathers': 936,\n",
              " 'destroyed': 937,\n",
              " 'prisoners': 938,\n",
              " 'excellency': 939,\n",
              " 'explain': 940,\n",
              " 'broken': 941,\n",
              " 'office': 942,\n",
              " 'kissed': 943,\n",
              " 'resulting': 944,\n",
              " 'divided': 945,\n",
              " 'sure': 946,\n",
              " 'master': 947,\n",
              " 'expected': 948,\n",
              " 'latter': 949,\n",
              " 'danger': 950,\n",
              " 'ball': 951,\n",
              " 'thoughts': 952,\n",
              " 'uniform': 953,\n",
              " 'portion': 954,\n",
              " 'seven': 955,\n",
              " 'purpose': 956,\n",
              " 'hes': 957,\n",
              " 'everybody': 958,\n",
              " 'occurred': 959,\n",
              " 'pressed': 960,\n",
              " 'asking': 961,\n",
              " 'established': 962,\n",
              " 'persons': 963,\n",
              " 'majority': 964,\n",
              " 'produce': 965,\n",
              " 'arrived': 966,\n",
              " 'weeks': 967,\n",
              " 'book': 968,\n",
              " 'economic': 969,\n",
              " 'subcutaneous': 970,\n",
              " 'certainly': 971,\n",
              " 'silver': 972,\n",
              " 'gold': 973,\n",
              " 'individual': 974,\n",
              " 'mikhaylovna': 975,\n",
              " 'interests': 976,\n",
              " 'tomorrow': 977,\n",
              " 'legs': 978,\n",
              " 'quiet': 979,\n",
              " 'presented': 980,\n",
              " 'exclaimed': 981,\n",
              " 'remembered': 982,\n",
              " 'follow': 983,\n",
              " 'handsome': 984,\n",
              " 'easy': 985,\n",
              " 'rule': 986,\n",
              " 'spite': 987,\n",
              " 'control': 988,\n",
              " 'massachusetts': 989,\n",
              " 'written': 990,\n",
              " 'filled': 991,\n",
              " 'region': 992,\n",
              " 'distance': 993,\n",
              " 'meeting': 994,\n",
              " 'tariff': 995,\n",
              " 'occupied': 996,\n",
              " 'lying': 997,\n",
              " 'importance': 998,\n",
              " 'church': 999,\n",
              " 'seem': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.split('\\n')[:10000]"
      ],
      "metadata": {
        "id": "mJGCpV92Yz0V"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequences(text, tokenizer):\n",
        "    for line in text.split('\\n'):\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            yield token_list[:i+1]\n"
      ],
      "metadata": {
        "id": "QGwBKkjMY3OT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "max_seq_len = 100\n",
        "\n",
        "for line in text.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, min(len(token_list), max_seq_len)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "ZMLPu9jkZhBl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#maximum sentence length\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "# input sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:51:33.799977Z",
          "iopub.execute_input": "2025-07-14T15:51:33.800217Z",
          "iopub.status.idle": "2025-07-14T15:51:35.863285Z",
          "shell.execute_reply.started": "2025-07-14T15:51:33.800200Z",
          "shell.execute_reply": "2025-07-14T15:51:35.862406Z"
        },
        "id": "2vj24J4ZrdwL"
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:51:35.864594Z",
          "iopub.execute_input": "2025-07-14T15:51:35.864901Z",
          "iopub.status.idle": "2025-07-14T15:51:35.868774Z",
          "shell.execute_reply.started": "2025-07-14T15:51:35.864875Z",
          "shell.execute_reply": "2025-07-14T15:51:35.867948Z"
        },
        "id": "pIu3eCCMrdwL"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": [
        "## onehot encoding"
      ],
      "metadata": {
        "id": "2axuZobrrdwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert one-hot-encode\n",
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-14T15:51:36.358562Z",
          "iopub.execute_input": "2025-07-14T15:51:36.359250Z",
          "execution_failed": "2025-07-14T15:51:58.633Z"
        },
        "id": "N8TvWcb-rdwL"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-feMGEAjaVXm",
        "outputId": "28200b12-0134-4a69-c458-c086396f3249"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j7GEV5Macve",
        "outputId": "61a208ea-9f30-41e1-f272-01b590fe093a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35522"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model finetuning & architecture"
      ],
      "metadata": {
        "id": "Pe9AO9fBrdwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-07-14T15:51:58.633Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "-zVckyQzrdwL",
        "outputId": "e7ee3d64-dbbe-4668-c58a-e9497b64454d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, max_sequence_len - 1))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "3axb2cfca11d",
        "outputId": "8c1b1484-3b99-4cbc-cc32-c20c49f206dd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m3,552,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35522\u001b[0m)          │     \u001b[38;5;34m5,363,822\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,552,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35522</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,363,822</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,199,868\u001b[0m (103.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,199,868</span> (103.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,066,622\u001b[0m (34.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,066,622</span> (34.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m18,133,246\u001b[0m (69.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,133,246</span> (69.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-07-14T15:51:58.634Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUpmtmhGrdwL",
        "outputId": "441fb0f1-a116-45d5-a59b-8e5d9e5106ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.0927 - loss: 4.1160\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0615 - loss: 4.1035\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1021 - loss: 3.9653\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0657 - loss: 4.0221\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0896 - loss: 4.0417\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0802 - loss: 4.0332\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0802 - loss: 4.0099\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0771 - loss: 4.0300\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0865 - loss: 4.0572\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0927 - loss: 3.9580\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0771 - loss: 4.0295\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0740 - loss: 4.0761\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0711 - loss: 4.0661\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0494 - loss: 4.0122\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0834 - loss: 4.0168\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0771 - loss: 4.0313\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0771 - loss: 3.9852\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0677 - loss: 4.0233\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1052 - loss: 4.0029\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0688 - loss: 3.9757\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0927 - loss: 3.9456\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0625 - loss: 4.0238\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0646 - loss: 3.9805\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0657 - loss: 3.9998\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0834 - loss: 3.9380\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0802 - loss: 3.9710\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0802 - loss: 3.9637\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0896 - loss: 3.9517\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0865 - loss: 3.9777\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0709 - loss: 3.9462\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1084 - loss: 3.8557\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0813 - loss: 3.9433\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0865 - loss: 3.8826\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0959 - loss: 3.8666\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0990 - loss: 3.8512\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0740 - loss: 3.8819\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0834 - loss: 3.8408\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1115 - loss: 3.8341\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0646 - loss: 3.8767\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0865 - loss: 3.8258\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0865 - loss: 3.8510\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0771 - loss: 3.8746\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0646 - loss: 3.8451\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0896 - loss: 3.7637\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0801 - loss: 3.8001\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0832 - loss: 3.7468\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0770 - loss: 3.7762\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0926 - loss: 3.7440\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0977 - loss: 3.6841\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1050 - loss: 3.7138\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1112 - loss: 3.6616\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0987 - loss: 3.6798\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0987 - loss: 3.6755\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0987 - loss: 3.6250\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1019 - loss: 3.5813\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1174 - loss: 3.6094\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0840 - loss: 3.6297\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1050 - loss: 3.5956\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1112 - loss: 3.5494\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0740 - loss: 3.5718\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0677 - loss: 3.5374\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0749 - loss: 3.5763\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0843 - loss: 3.5601\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0676 - loss: 3.5806\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0832 - loss: 3.5027\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0904 - loss: 3.5308\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1123 - loss: 3.4619\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1205 - loss: 3.4509\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0924 - loss: 3.4490\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1214 - loss: 3.4213\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1234 - loss: 3.4149\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1184 - loss: 3.3405\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1080 - loss: 3.3806\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1174 - loss: 3.3030\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0922 - loss: 3.3607\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1605 - loss: 3.3384\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1451 - loss: 3.3101\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1421 - loss: 3.2404\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1399 - loss: 3.2598\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1275 - loss: 3.2560\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1077 - loss: 3.2169\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1244 - loss: 3.2051\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1109 - loss: 3.1780\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1327 - loss: 3.1278\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1450 - loss: 3.1137\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1730 - loss: 3.0917\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1973 - loss: 3.0840\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2481 - loss: 3.0440\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2096 - loss: 3.0673\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2410 - loss: 3.0343\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2769 - loss: 2.9849\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2343 - loss: 2.9876\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2139 - loss: 2.9138\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2513 - loss: 2.8316\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2688 - loss: 2.8837\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2780 - loss: 2.8355\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2426 - loss: 2.8677\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2699 - loss: 2.7844\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2541 - loss: 2.8209\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1882 - loss: 2.7783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e19d7601950>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference"
      ],
      "metadata": {
        "id": "NTpBS2lIrdwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#determine a text\n",
        "seed_text = \"I will close the door if\"\n",
        "# predict word number\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "    #convert to token\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    #path sequences\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    #model prediction\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    # get predict words\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-07-14T15:51:58.634Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKIVfwzErdwL",
        "outputId": "5c445833-bda0-48df-ffd8-4be119e70c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
          ]
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hpq5WSDXrdwM",
        "outputId": "a10a7d45-066d-4d20-a944-2644ccdd76db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I will close the door if copyright copyright arthur the copyright copyright arthur the copyright copyright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s7NXMwvXZ1tR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}